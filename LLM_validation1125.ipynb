{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27aef8d-75f8-427b-a81b-5476eadd0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from openai import OpenAI, RateLimitError, APIError\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_DATA_PATH = \"/data/users_data/mli13/LLMvalidationAD112025/drug_disease_long_format_20250325_190703.csv\"\n",
    "ABSTRACT_OUTPUT_PATH = \"/data/users_data/mli13/LLMvalidationAD112025/result112025/realtime_abstract_analysis.csv\"\n",
    "SUMMARY_OUTPUT_PATH = \"/data/users_data/mli13/LLMvalidationAD112025/result112025/realtime_summary_analysis.csv\"\n",
    "API_KEY_PATH = '/data/users_data/mli13/LLMvalidationAD112025/openai_api.txt'\n",
    "\n",
    "\n",
    "# Set OpenAI API key\n",
    "with open(API_KEY_PATH, 'r') as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "mode = \"response\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def construct_comprehensive_prompt(row, abstract):\n",
    "    \"\"\"\n",
    "    Revised prompt to strictly limit external knowledge.\n",
    "    \"\"\"\n",
    "    drug_name = row['Drug_name']\n",
    "    disease_name = row['Disease_name']\n",
    "\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are an expert biomedical researcher. Your task is to determine whether {drug_name} is effective \"\n",
    "        f\"against {disease_name}.\\n\\n\"\n",
    "        f\"CRITICAL INSTRUCTION: Answer strictly based ONLY on the provided text below. \"\n",
    "        f\"Do not use outside knowledge or prior training data regarding this drug or disease. \"\n",
    "        f\"If the abstract does not explicitly state the drug is effective for this specific disease, classify as Neutral.\\n\"\n",
    "        f\"--- BEGIN PROVIDED TEXT ---\\n\"\n",
    "        f\"[Drug Info]: {drug_name}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Add key drug information fields\n",
    "    key_fields = ['description', 'mechanism_of_action', 'protein_binding', 'pharmacodynamics', 'category']\n",
    "    for field in key_fields:\n",
    "        if field in row and pd.notnull(row[field]) and row[field]:\n",
    "            value = str(row[field])\n",
    "            # # Limit length of very long text\n",
    "            # if len(value) > 300:\n",
    "            #     value = value[:300] + \"...\"\n",
    "            prompt += f\"{field.replace('_', ' ').title()}: {value}\\n\"\n",
    "\n",
    "    # Add drug synonyms\n",
    "    drug_synonyms = []\n",
    "    for i in range(1, 11):  # drug_synonym1 through drug_synonym21\n",
    "        syn_col = f\"drug_synonym{i}\"\n",
    "        if syn_col in row and pd.notnull(row[syn_col]) and row[syn_col]:\n",
    "            drug_synonyms.append(str(row[syn_col]))\n",
    "\n",
    "    if drug_synonyms:\n",
    "        prompt += f\"Drug Synonyms: {', '.join(drug_synonyms)}\\n\"\n",
    "\n",
    "    # Add disease information\n",
    "    prompt += f\"\\nDISEASE INFORMATION:\\n\"\n",
    "    prompt += f\"Disease: {disease_name}\\n\"\n",
    "\n",
    "    # Add disease synonyms\n",
    "    disease_synonyms = []\n",
    "    for i in range(1, 11):  # disease_synonym1 through disease_synonym15\n",
    "        syn_col = f\"disease_synonym{i}\"\n",
    "        if syn_col in row and pd.notnull(row[syn_col]) and row[syn_col]:\n",
    "            disease_synonyms.append(str(row[syn_col]))\n",
    "\n",
    "    if disease_synonyms:\n",
    "        prompt += f\"Disease Synonyms: {', '.join(disease_synonyms)}\\n\"\n",
    "\n",
    "    prompt += f\"[Abstract]: {abstract}\\n\"\n",
    "    prompt += f\"--- END PROVIDED TEXT ---\\n\\n\"\n",
    "\n",
    "    # Add conclusion request\n",
    "    #prompt += (\n",
    "     #   \"Based primarily on the abstract, and considering the drug and disease information provided, \"\n",
    "      #  \"assess whether the drug is effective for the disease. Provide your assessment in the following format:\\n\\n\"\n",
    "       # \"Result: [Positive/Neutral/Negative] (Choose exactly one, where Positive means the drug is effective, \"\n",
    "        #\"Neutral means uncertain or insufficient evidence, and Negative means the drug is ineffective or harmful)\\n\"\n",
    "     #   \"Explanation: [provide a brief explanation in 2-3 sentences focusing mainly on evidence from the abstract]\"\n",
    "    #)\n",
    "\n",
    "    #return prompt\n",
    "\n",
    "    prompt += (\n",
    "        \"Based solely on the text delimited above, provide your assessment in the following format:\\n\\n\"\n",
    "        \"Result: [Positive/Neutral/Negative] \\n\"\n",
    "        \"(Definitions: \\n\"\n",
    "        \"- Positive: The text explicitly indicates the drug is effective.\\n\"\n",
    "        \"- Neutral: The text is uncertain, provides insufficient evidence, or describes a study with no clear conclusion.\\n\"\n",
    "        \"- Negative: The text indicates the drug is harmful or ineffective.)\\n\\n\"\n",
    "        \"Explanation: Provide a brief explanation in 2-3 sentences citing specific evidence strictly from the provided abstract.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def call_gpt_with_retry(prompt, mode, max_retries=5):\n",
    "    \"\"\"\n",
    "    Calls the GPT-4o API with exponential backoff retry logic for rate limits.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if mode == \"chat\":\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=0.1,  # Lower temperature for more consistent results\n",
    "                )\n",
    "                return completion.choices[0].message.content.strip()\n",
    "            elif mode == \"response\":\n",
    "                response = client.responses.create(\n",
    "                    model=\"gpt-4.1\",\n",
    "                    input=prompt,\n",
    "                    temperature=0.2,  # Lower temperature for more consistent results\n",
    "                )\n",
    "                # Extract text from the output\n",
    "                for item in response.output:\n",
    "                    if hasattr(item, \"type\") and item.type == \"message\":\n",
    "                        if hasattr(item, \"content\"):\n",
    "                            for content_item in item.content:\n",
    "                                if hasattr(content_item, \"text\"):\n",
    "                                    return content_item.text.strip()\n",
    "                return \"No output found in response structure.\"\n",
    "            elif mode == \"response_web\":\n",
    "                response = client.responses.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    tools=[{\"type\": \"web_search_preview\"}],\n",
    "                    input=prompt,\n",
    "                    temperature=0.1,  # Lower temperature for more consistent results\n",
    "                )\n",
    "                # Extract text from the output\n",
    "                for item in response.output:\n",
    "                    if hasattr(item, \"type\") and item.type == \"message\":\n",
    "                        if hasattr(item, \"content\"):\n",
    "                            for content_item in item.content:\n",
    "                                if hasattr(content_item, \"text\"):\n",
    "                                    return content_item.text.strip()\n",
    "                return \"No output found in response structure.\"\n",
    "            else:\n",
    "                raise ValueError(\"Invalid mode selected.\")\n",
    "\n",
    "        except RateLimitError as e:\n",
    "            print(f\"Rate limit error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "\n",
    "            # If we've reached the max retries, just return the error\n",
    "            if attempt == max_retries - 1:\n",
    "                return f\"API call error after {max_retries} attempts: {str(e)}\"\n",
    "\n",
    "            # Exponential backoff with jitter\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1) + 20  # Longer wait for rate limits\n",
    "            print(f\"Waiting {wait_time:.2f} seconds before retrying...\")\n",
    "            time.sleep(wait_time)\n",
    "        except APIError as e:\n",
    "            print(f\"API error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "\n",
    "            # If we've reached the max retries, just return the error\n",
    "            if attempt == max_retries - 1:\n",
    "                return f\"API call error after {max_retries} attempts: {str(e)}\"\n",
    "\n",
    "            # Standard backoff with jitter\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1) + 5\n",
    "            print(f\"Waiting {wait_time:.2f} seconds before retrying...\")\n",
    "            time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "\n",
    "            # If we've reached the max retries, just return the error\n",
    "            if attempt == max_retries - 1:\n",
    "                return f\"API call error after {max_retries} attempts: {str(e)}\"\n",
    "\n",
    "            # Shorter wait for non-rate-limit errors\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "            print(f\"Waiting {wait_time:.2f} seconds before retrying...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    return \"Failed after maximum retry attempts\"\n",
    "\n",
    "def parse_assessment_output(output):\n",
    "    \"\"\"\n",
    "    Parse the assessment output to extract Result and Explanation.\n",
    "    Expected format:\n",
    "    Result: [Positive/Neutral/Negative]\n",
    "    Explanation: [explanation]\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    result = \"Unknown\"\n",
    "    explanation = \"\"\n",
    "\n",
    "    if output and not output.startswith(\"API call error\"):\n",
    "        # Try to find Result section using case-insensitive matching\n",
    "        result_match = re.search(r'result:\\s*(positive|neutral|negative)', output.lower())\n",
    "        if result_match:\n",
    "            result_value = result_match.group(1)\n",
    "            # Convert to proper case format\n",
    "            result = result_value.capitalize()\n",
    "\n",
    "        # Try alternate format if not found (sometimes GPT outputs \"Result - Positive\" format)\n",
    "        if result == \"Unknown\":\n",
    "            alt_result_match = re.search(r'result\\s*[-:]\\s*(positive|neutral|negative)', output.lower())\n",
    "            if alt_result_match:\n",
    "                result_value = alt_result_match.group(1)\n",
    "                result = result_value.capitalize()\n",
    "\n",
    "        # Try to find Explanation section using case-insensitive matching\n",
    "        explanation_match = re.search(r'explanation:\\s*(.*?)(?:\\n\\n|\\n*$)', output, re.IGNORECASE | re.DOTALL)\n",
    "        if explanation_match:\n",
    "            explanation = explanation_match.group(1).strip()\n",
    "        else:\n",
    "            # Try alternate format or look for any text after the result\n",
    "            after_result = re.search(r'(positive|neutral|negative)[.:]\\s*(.*?)(?:\\n\\n|\\n*$)', output.lower(), re.DOTALL)\n",
    "            if after_result:\n",
    "                explanation = after_result.group(2).strip()\n",
    "\n",
    "    # If parsing failed, return the whole output as explanation\n",
    "    if result == \"Unknown\" and not explanation:\n",
    "        explanation = output\n",
    "        # Make final attempt to extract result from the text\n",
    "        if \"positive\" in output.lower() and \"negative\" not in output.lower():\n",
    "            result = \"Positive\"\n",
    "        elif \"negative\" in output.lower() and \"positive\" not in output.lower():\n",
    "            result = \"Negative\"\n",
    "        elif \"neutral\" in output.lower() or \"insufficient evidence\" in output.lower():\n",
    "            result = \"Neutral\"\n",
    "\n",
    "    return result, explanation\n",
    "\n",
    "# --- MAIN ANALYSIS FUNCTION ---\n",
    "\n",
    "def analyze_drug_disease_abstracts(df, mode=\"response\", filter_disease=None, filter_drug=None, batch_size=5, max_abstracts_per_pair=50):\n",
    "    \n",
    "    # 1. LOAD PREVIOUS RESULTS (RESUME LOGIC)\n",
    "    processed_cache = {} # Key: (Drug, Disease, PMID) -> Row Dict\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(os.path.dirname(ABSTRACT_OUTPUT_PATH), exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(ABSTRACT_OUTPUT_PATH):\n",
    "        print(\"Loading existing results to resume...\")\n",
    "        try:\n",
    "            existing_df = pd.read_csv(ABSTRACT_OUTPUT_PATH, on_bad_lines='skip')\n",
    "            for _, row in existing_df.iterrows():\n",
    "                # Create a unique key for each processed item\n",
    "                key = (str(row['Drug_name']), str(row['Disease_name']), str(row['PubMed_ID']))\n",
    "                processed_cache[key] = row.to_dict()\n",
    "            print(f\"Loaded {len(processed_cache)} previously processed abstracts.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read existing file: {e}. Starting fresh.\")\n",
    "    else:\n",
    "        # Initialize file with headers\n",
    "        pd.DataFrame(columns=[\"Drug_ID\", \"Drug_name\", \"Disease_ID\", \"Disease_name\", \"PubMed_ID\", \"Title\", \"Model\", \"Result\", \"Explanation\", \"Raw_Output\"]).to_csv(ABSTRACT_OUTPUT_PATH, index=False)\n",
    "        pd.DataFrame(columns=[\"Drug_ID\", \"Drug_name\", \"Disease_ID\", \"Disease_name\", \"Model\", \"Total_Abstracts\", \"Analyzed\", \"Positive\", \"Neutral\", \"Negative\", \"Overall_Assessment\"]).to_csv(SUMMARY_OUTPUT_PATH, index=False)\n",
    "\n",
    "    # 2. FILTERING\n",
    "    if filter_disease:\n",
    "        if isinstance(filter_disease, str):\n",
    "            df_filtered = df[df['Disease_name'].str.contains(filter_disease, case=False)]\n",
    "        elif isinstance(filter_disease, list):\n",
    "            df_filtered = df[df['Disease_name'].isin(filter_disease)]\n",
    "    else:\n",
    "        df_filtered = df\n",
    "\n",
    "    if filter_drug:\n",
    "        if isinstance(filter_drug, str):\n",
    "            df_filtered = df_filtered[df_filtered['Drug_name'].str.contains(filter_drug, case=False)]\n",
    "        elif isinstance(filter_drug, list):\n",
    "            df_filtered = df_filtered[df_filtered['Drug_name'].isin(filter_drug)]\n",
    "    \n",
    "    print(f\"Processing {len(df_filtered)} rows after filtering\")\n",
    "\n",
    "    # 3. GROUPING\n",
    "    def standardize_value(val):\n",
    "        if pd.isna(val) or (isinstance(val, str) and val.lower() in ('none', 'null', '')):\n",
    "            return 'Missing_Value'\n",
    "        return val\n",
    "\n",
    "    df_for_grouping = df_filtered.copy()\n",
    "    df_for_grouping['Drug_ID'] = df_for_grouping['Drug_ID'].apply(standardize_value)\n",
    "    df_for_grouping['Disease_ID'] = df_for_grouping['Disease_ID'].apply(standardize_value)\n",
    "    df_for_grouping['Model'] = df_for_grouping['Model'].apply(standardize_value)\n",
    "\n",
    "    pairs_with_count = df_filtered.groupby(['Drug_ID', 'Disease_ID', 'Model']).agg({\n",
    "        'Drug_name': 'first',\n",
    "        'Disease_name': 'first',\n",
    "        'pubmed_id_count': 'first',\n",
    "        'pubmed_id': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    pairs_with_count.rename(columns={'pubmed_id': 'available_abstracts'}, inplace=True)\n",
    "    pairs_with_count = pairs_with_count.sort_values(['Disease_name', 'Drug_name'])\n",
    "\n",
    "    print(f\"Found {len(pairs_with_count)} unique drug-disease-model pairs\")\n",
    "\n",
    "    # 4. PROCESSING LOOP\n",
    "    for _, pair_row in pairs_with_count.iterrows():\n",
    "        drug_id = pair_row['Drug_ID']\n",
    "        disease_id = pair_row['Disease_ID']\n",
    "        model = pair_row['Model']\n",
    "        drug_name = pair_row['Drug_name']\n",
    "        disease_name = pair_row['Disease_name']\n",
    "        \n",
    "        # Re-select rows for this group\n",
    "        def is_val(row_val, target):\n",
    "            std_val = standardize_value(row_val)\n",
    "            return std_val == standardize_value(target)\n",
    "\n",
    "        # Filter manually to be safe with NaNs\n",
    "        mask = (df_filtered['Drug_ID'].apply(lambda x: is_val(x, drug_id)) & \n",
    "                df_filtered['Disease_ID'].apply(lambda x: is_val(x, disease_id)) &\n",
    "                df_filtered['Model'].apply(lambda x: is_val(x, model)))\n",
    "        \n",
    "        group = df_filtered[mask]\n",
    "\n",
    "        if len(group) > max_abstracts_per_pair:\n",
    "            group = group.head(max_abstracts_per_pair)\n",
    "\n",
    "        print(f\"\\nAnalyzing {drug_name} for {disease_name} ({len(group)} abstracts)\")\n",
    "\n",
    "        pair_results = []\n",
    "        \n",
    "        # Batch processing\n",
    "        for batch_idx, batch_df in enumerate(np.array_split(group, max(1, len(group) // batch_size))):\n",
    "            for idx, row in batch_df.iterrows():\n",
    "                pubmed_id = str(row.get('pubmed_id', 'Unknown'))\n",
    "                title = row.get('title', 'No title')\n",
    "                \n",
    "                # CHECK CACHE\n",
    "                cache_key = (str(drug_name), str(disease_name), pubmed_id)\n",
    "                \n",
    "                if cache_key in processed_cache:\n",
    "                    # Abstract already processed, load from cache\n",
    "                    # print(f\"  Skipping {pubmed_id} (Already processed)\")\n",
    "                    pair_results.append(processed_cache[cache_key])\n",
    "                    continue\n",
    "\n",
    "                # Not in cache, process it\n",
    "                print(f\"  Processing new abstract: {pubmed_id}\")\n",
    "                \n",
    "                abstract_text = row.get('abstract', '')\n",
    "                if pd.isnull(abstract_text) or len(str(abstract_text)) < 50:\n",
    "                    title_text = row.get('title', '')\n",
    "                    abstract_text = f\"TITLE ONLY: {title_text}\"\n",
    "                \n",
    "                prompt = construct_comprehensive_prompt(row, abstract_text)\n",
    "                output = call_gpt_with_retry(prompt, mode)\n",
    "                result, explanation = parse_assessment_output(output)\n",
    "\n",
    "                # Create result object\n",
    "                abstract_result = {\n",
    "                    \"Drug_ID\": drug_id,\n",
    "                    \"Drug_name\": drug_name,\n",
    "                    \"Disease_ID\": disease_id,\n",
    "                    \"Disease_name\": disease_name,\n",
    "                    \"PubMed_ID\": pubmed_id,\n",
    "                    \"Title\": title,\n",
    "                    \"Model\": model,\n",
    "                    \"Result\": result,\n",
    "                    \"Explanation\": explanation,\n",
    "                    \"Raw_Output\": output\n",
    "                }\n",
    "                \n",
    "                # Save IMMEIDATELY to disk\n",
    "                pd.DataFrame([abstract_result]).to_csv(ABSTRACT_OUTPUT_PATH, mode='a', header=False, index=False)\n",
    "                \n",
    "                # Add to memory for stats\n",
    "                pair_results.append(abstract_result)\n",
    "                \n",
    "                # Add to cache so we don't re-process if we crash later in this same group\n",
    "                processed_cache[cache_key] = abstract_result\n",
    "\n",
    "            # Pause between batches if we actually made calls\n",
    "            if batch_idx < max(1, len(group) // batch_size) - 1:\n",
    "                time.sleep(1)\n",
    "\n",
    "        # 5. GENERATE & SAVE STATISTICS (Once group is done)\n",
    "        if pair_results:\n",
    "            counts = Counter([str(r.get(\"Result\", \"Unknown\")).capitalize() for r in pair_results])\n",
    "            total = len(pair_results)\n",
    "            \n",
    "            pos_pct = (counts.get(\"Positive\", 0) / total) * 100\n",
    "            neg_pct = (counts.get(\"Negative\", 0) / total) * 100\n",
    "            neu_pct = (counts.get(\"Neutral\", 0) / total) * 100\n",
    "            \n",
    "            overall = \"Inconclusive\"\n",
    "            if pos_pct >= 60: overall = \"Positive\"\n",
    "            elif neg_pct >= 60: overall = \"Negative\"\n",
    "            elif neu_pct >= 60: overall = \"Neutral\"\n",
    "            elif (pos_pct > neu_pct + 20 and pos_pct > neg_pct + 20): overall = \"Likely Positive\"\n",
    "            elif (neg_pct > neu_pct + 20 and neg_pct > pos_pct + 20): overall = \"Likely Negative\"\n",
    "\n",
    "            summary_row = {\n",
    "                \"Drug_ID\": drug_id,\n",
    "                \"Drug_name\": drug_name,\n",
    "                \"Disease_ID\": disease_id,\n",
    "                \"Disease_name\": disease_name,\n",
    "                \"Model\": model,\n",
    "                \"Total_Abstracts\": len(group),\n",
    "                \"Analyzed\": total,\n",
    "                \"Positive\": counts.get(\"Positive\", 0),\n",
    "                \"Neutral\": counts.get(\"Neutral\", 0),\n",
    "                \"Negative\": counts.get(\"Negative\", 0),\n",
    "                \"Overall_Assessment\": overall\n",
    "            }\n",
    "            \n",
    "            # Save Summary immediately\n",
    "            pd.DataFrame([summary_row]).to_csv(SUMMARY_OUTPUT_PATH, mode='a', header=not os.path.exists(SUMMARY_OUTPUT_PATH), index=False)\n",
    "            \n",
    "            print(f\"  -> Stats: Pos: {pos_pct:.1f}% | Neu: {neu_pct:.1f}% | Neg: {neg_pct:.1f}% -> {overall}\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(INPUT_DATA_PATH):\n",
    "        print(f\"Loading data from {INPUT_DATA_PATH}...\")\n",
    "        df_full = pd.read_csv(INPUT_DATA_PATH)\n",
    "        \n",
    "        analyze_drug_disease_abstracts(\n",
    "            df_full, \n",
    "            mode=\"response\",\n",
    "            batch_size=5,\n",
    "            max_abstracts_per_pair=200\n",
    "        )\n",
    "        print(\"Analysis completed.\")\n",
    "    else:\n",
    "        print(f\"Error: Input file not found at {INPUT_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05163c-f2be-4b9e-b2ce-36d0694b3755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmenv)",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
